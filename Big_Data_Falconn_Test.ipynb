{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Big_Data_Falconn_Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b4tiMKzkA7e"
      },
      "source": [
        "# Author Markus Laubenthal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARAmpLtYeZd1"
      },
      "source": [
        "!pip install falconn\n",
        "!pip install annoy\n",
        "!mkdir -p input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obpVklN5ohfV"
      },
      "source": [
        "!rm -rf functions\n",
        "!git clone https://github.com/Lennard-Alms/lab_bd.git functions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzhLXOEKmkIl"
      },
      "source": [
        "# !wget https://storage.googleapis.com/laubenthal_spatiolab/feature_vectors_75.h5 -O input/feature_vectors_75.h5 --no-verbose\n",
        "!wget https://storage.googleapis.com/laubenthal_spatiolab/duplicates.h5 -O input/duplicates.h5 --no-verbose\n",
        "!wget https://storage.googleapis.com/laubenthal_spatiolab/final_test.h5 -O input/final_test.h5 --no-verbose\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOH8u6G-o1F5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "from sklearn.metrics import jaccard_score\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import h5py\n",
        "import keras\n",
        "from keras.layers import Input\n",
        "from keras import backend as K\n",
        "from keras import layers\n",
        "import gc\n",
        "from scipy.spatial import distance_matrix\n",
        "import seaborn as sns\n",
        "from operator import itemgetter \n",
        "from google.colab.patches import cv2_imshow\n",
        "from functions.preprocessing.BatchToFile import BatchProcessToFile\n",
        "from functions.preprocessing.FeatureExtractor import VGGFeatureExtractorMax\n",
        "from functions.preprocessing.FeatureExtracorMaxNoPatches import VGGFeatureExtractorMaxNoPatches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur2GpdKKnlmo"
      },
      "source": [
        "from falconn import LSHIndex, LSHConstructionParameters, get_default_parameters\n",
        "import falconn\n",
        "from annoy import AnnoyIndex\n",
        "from functions.preprocessing.ImageMutation import PatchMutation\n",
        "from functions.preprocessing.HelperFunctions import get_patches_from_image\n",
        "from functions.postprocessing.ErrorEvaluation import evaluate_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HDtawr0Mgb1"
      },
      "source": [
        "f = h5py.File('input/duplicates.h5', 'r')\n",
        "for key in f.keys():\n",
        "  print(key)\n",
        "f.close()\n",
        "\n",
        "\n",
        "print(\"---\")\n",
        "f = h5py.File('input/final_test.h5', 'r')\n",
        "for key in f.keys():\n",
        "  print(key)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfKp2hBpQKT1"
      },
      "source": [
        "f = h5py.File('input/duplicates.h5', 'r')\n",
        "g = h5py.File('input/final_test.h5', 'r')\n",
        "vectors = f['a2d2_background_horses_50_cover'][:].astype(np.float32)\n",
        "labels = f['a2d2_background_horses_50_cover_label'][:].astype(np.float32)\n",
        "queries = f['query(200, 200)'][:].astype(np.float32)\n",
        "query_labels = np.arange(0, queries.shape[0]) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL0LMKh7hOZU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HFjNwmVLY9Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8fpRx8CS7x-"
      },
      "source": [
        "def do_query(query_vector):\n",
        "  global query_labels\n",
        "  query_index = 0\n",
        "  query = lsh_index.construct_query_object()\n",
        "  # query.set_num_probes(70)\n",
        "  candidates = np.array(query.get_unique_candidates(query_vector))\n",
        "  return candidates\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_hash_candidates(candidates, filtered, query_vector, vectors, ground_truth = None):\n",
        "  if ground_truth is None:\n",
        "    ground_truth = filter_results(vectors, np.arange(0, vectors.shape[0]), query_vector, threshold).flatten()\n",
        "  database_size = vectors.shape[0]\n",
        "  query_size = candidates.shape[0]\n",
        "  filtered_size = filtered.shape[0]\n",
        "\n",
        "\n",
        "  false_positives = query_size - filtered_size\n",
        "  false_negatives = ground_truth.shape[0] - filtered_size\n",
        "\n",
        "  #recall = 100 / ground_truth.shape[0] * filtered_size / 100\n",
        "  query_ratio = 100 / database_size * query_size / 100\n",
        "  # relevant_ratio = 100 / query_size * filtered_size / 100\n",
        "  relevant_ratio = 0\n",
        "  return 0, query_ratio, relevant_ratio, false_positives, false_negatives\n",
        "\n",
        "def calculate_cosine_sim(feature_vectors, feature_vectors_b = None):\n",
        "  if feature_vectors_b is None:\n",
        "    feature_vectors_b = feature_vectors.copy()\n",
        "  norms = np.linalg.norm(feature_vectors, axis=1)\n",
        "  norms_b = np.linalg.norm(feature_vectors_b, axis=1)\n",
        "  angle_matrix = (np.dot(feature_vectors, feature_vectors_b.T) / np.dot(norms[:,np.newaxis], norms_b[np.newaxis, :])).clip(-1,1)\n",
        "  angle_matrix = np.arccos(angle_matrix)\n",
        "  return angle_matrix\n",
        "\n",
        "def filter_results(vectors, result_ids, query, threshold):\n",
        "  selection = vectors[result_ids]\n",
        "  cosine_sim = calculate_cosine_sim(selection, query[np.newaxis, :]).flatten()\n",
        "  filter = np.argwhere(cosine_sim < threshold)\n",
        "  return result_ids[filter]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZP-nl9bQKwH"
      },
      "source": [
        "params = get_default_parameters(\n",
        "    num_points = vectors.shape[0],\n",
        "    dimension = vectors.shape[1],\n",
        "    distance=falconn.DistanceFunction.NegativeInnerProduct)\n",
        "params.lsh_family = falconn.LSHFamily.Hyperplane\n",
        "params.k = 20\n",
        "params.l = 50\n",
        "\n",
        "print(params.k)\n",
        "print(params.l)\n",
        "lsh_index = LSHIndex(params)\n",
        "lsh_index.setup(vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoA4nWjA_F4W"
      },
      "source": [
        "# NEAR DUPLICATE TEST\n",
        "\n",
        "query_index = 0\n",
        "query_vector = queries[query_index]\n",
        "candidates = do_query(query_vector)\n",
        "for threshold in np.arange(0.6, 1, 0.1):\n",
        "\n",
        "  query_label = query_labels[query_index]\n",
        "\n",
        "  filtered = filter_results(vectors, candidates, query_vector, threshold).flatten()\n",
        "  ground_truth = filter_results(vectors, np.arange(0, vectors.shape[0]), query_vector, threshold).flatten()\n",
        "\n",
        "  recall, query_ratio, relevant_ratio, fp, fn = evaluate_hash_candidates(candidates, filtered, query_vector, vectors)\n",
        "  sc,ic = evaluate_result(filtered, labels, query_label)\n",
        "  precision, recall, accuracy = sc[0], sc[1], sc[2]\n",
        "\n",
        "  print(\"Results for threshold: \", threshold)\n",
        "  print(\"Recall:                \", recall)\n",
        "  print(\"Precision:             \", precision)\n",
        "  print(\"Accuracy:              \", accuracy)\n",
        "  print(\"Queried % of database: \", query_ratio)\n",
        "  print(\"True Positive Ratio:   \", relevant_ratio)\n",
        "  print(\"FP / FN:               \", fp, fn)\n",
        "  print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O28t_jX-BvD"
      },
      "source": [
        "# NEAR DUPLICATE EVALUATION WITH ALL QUERIES\n",
        "nd_precisions = []\n",
        "nd_recalls = []\n",
        "nd_accuracies = []\n",
        "\n",
        "nd_precisions_gem = []\n",
        "nd_recalls_gem = []\n",
        "nd_accuracies_gem = []\n",
        "\n",
        "query_index = 0\n",
        "for threshold in np.arange(0, 15, 0.1):\n",
        "  mean_precision = 0\n",
        "  mean_recall = 0\n",
        "  mean_accuracy = 0\n",
        "  mean_query_ratio = 0\n",
        "  mean_relevant_ratio = 0\n",
        "\n",
        "  gemmean_precision = 0\n",
        "  gemmean_recall = 0\n",
        "  gemmean_accuracy = 0\n",
        "  gemmean_query_ratio = 0\n",
        "  gemmean_relevant_ratio = 0\n",
        "\n",
        "  indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
        "  # indices = range(queries.shape[0])\n",
        "\n",
        "  for query_index in indices:\n",
        "\n",
        "    query_vector = queries[query_index]\n",
        "    query_label = query_labels[query_index]\n",
        "    candidates = do_query(query_vector)\n",
        "\n",
        "    filtered = filter_results(vectors, candidates, query_vector, threshold / 10).flatten()\n",
        "    ground_truth = filter_results(vectors, np.arange(0, vectors.shape[0]), query_vector, threshold / 10).flatten()\n",
        "    \n",
        "    recall, query_ratio, relevant_ratio, fp, fn = evaluate_hash_candidates(candidates, filtered, query_vector, vectors)\n",
        "    sc,ic = evaluate_result(filtered, labels, query_label)\n",
        "    gsc,gic = evaluate_result(ground_truth, labels, query_label)\n",
        "\n",
        "    precision, recall, accuracy = sc[0], sc[1], sc[2]\n",
        "    mean_precision = mean_precision + precision\n",
        "    mean_recall = mean_recall + recall\n",
        "    mean_accuracy = mean_accuracy + accuracy\n",
        "    mean_query_ratio = mean_query_ratio + query_ratio\n",
        "    mean_relevant_ratio = mean_relevant_ratio + relevant_ratio\n",
        "\n",
        "    gemprecision, gemrecall, gemaccuracy = gsc[0], gsc[1], gsc[2]\n",
        "    gemmean_precision = gemmean_precision + gemprecision\n",
        "    gemmean_recall = gemmean_recall + gemrecall\n",
        "    gemmean_accuracy = gemmean_accuracy + gemaccuracy\n",
        "\n",
        "  nd_precisions.append(mean_precision / len(indices))\n",
        "  nd_recalls.append(mean_recall / len(indices))\n",
        "  nd_accuracies.append(mean_accuracy / len(indices))\n",
        "\n",
        "  nd_precisions_gem.append(gemmean_precision / len(indices))\n",
        "  nd_recalls_gem.append(gemmean_recall / len(indices))\n",
        "  nd_accuracies_gem.append(gemmean_accuracy / len(indices))\n",
        "\n",
        "  print(\"Results for threshold: \", threshold / 10)\n",
        "  print(\"Recall:                \", mean_recall / len(indices))\n",
        "  print(\"Precision:             \", mean_precision / len(indices))\n",
        "  print(\"Accuracy:              \", mean_accuracy / len(indices))\n",
        "\n",
        "  print(\"gemRecall:             \", gemmean_recall / len(indices))\n",
        "  print(\"gemPrecision:          \", gemmean_precision / len(indices))\n",
        "  print(\"gemAccuracy:           \", gemmean_accuracy / len(indices))\n",
        "\n",
        "  print(\"Queried % of database: \", mean_query_ratio / len(indices))\n",
        "  print(\"True Positive Ratio:   \", mean_relevant_ratio / len(indices))\n",
        "  print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1-2NQqwixKz"
      },
      "source": [
        "x_axis = np.arange(0, 15, 0.1) / 10\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7,5))\n",
        "ax.plot(x_axis, nd_recalls, label=\"recall\")\n",
        "ax.plot(x_axis, nd_precisions, label=\"precision\")\n",
        "ax.plot(x_axis, nd_accuracies, label=\"accuracy\")\n",
        "ax.legend(loc=\"center left\")\n",
        "ax.set_xlabel('Cosine distance threshold')\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7,5))\n",
        "ax.plot(x_axis, nd_recalls_gem, label=\"recall\")\n",
        "ax.plot(x_axis, nd_precisions_gem, label=\"precision\")\n",
        "ax.plot(x_axis, nd_accuracies_gem, label=\"accuracy\")\n",
        "ax.legend(loc=\"center left\")\n",
        "ax.set_xlabel('Cosine distance threshold')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVTCeo3KY9aE"
      },
      "source": [
        "# NEAR DUPLICATE EVALUATION WITH ALL QUERIES AND QUERY SCALING\n",
        "\n",
        "nd_precisions = []\n",
        "nd_recalls = []\n",
        "nd_accuracies = []\n",
        "\n",
        "nd_precisions_gem = []\n",
        "nd_recalls_gem = []\n",
        "nd_accuracies_gem = []\n",
        "\n",
        "query_index = 0\n",
        "for threshold in np.arange(0, 15, 0.1):\n",
        "  mean_precision = 0\n",
        "  mean_recall = 0\n",
        "  mean_accuracy = 0\n",
        "  mean_query_ratio = 0\n",
        "  mean_relevant_ratio = 0\n",
        "\n",
        "  gemmean_precision = 0\n",
        "  gemmean_recall = 0\n",
        "  gemmean_accuracy = 0\n",
        "  gemmean_query_ratio = 0\n",
        "  gemmean_relevant_ratio = 0\n",
        "\n",
        "  indices = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
        "  # indices = range(queries.shape[0])\n",
        "\n",
        "  for query_index in indices:\n",
        "\n",
        "    query_vector = queries[query_index]\n",
        "    # query_vectors = [0] * len(q)\n",
        "    # for _i in range(len(q)):\n",
        "    #   query_vectors[_i] = q[_i][query_index]\n",
        "    query_label = query_labels[query_index]\n",
        "    candidates_list = []\n",
        "    # for query_vector in query_vectors:\n",
        "    #   candidates = do_query(query_vector)\n",
        "    #   candidates_list.append(candidates)\n",
        "    # candidates = np.concatenate(candidates_list)\n",
        "    # candidates = np.array(list(set(candidates)))\n",
        "\n",
        "    filtered = filter_results(vectors, candidates, query_vector, threshold / 10).flatten()\n",
        "    ground_truth = filter_results(vectors, np.arange(0, vectors.shape[0]), query_vector, threshold / 10).flatten()\n",
        "    \n",
        "    recall, query_ratio, relevant_ratio, fp, fn = evaluate_hash_candidates(candidates, filtered, query_vector, vectors)\n",
        "    sc,ic = evaluate_result(filtered, labels, query_label)\n",
        "    gsc,gic = evaluate_result(ground_truth, labels, query_label)\n",
        "\n",
        "    precision, recall, accuracy = sc[0], sc[1], sc[2]\n",
        "    mean_precision = mean_precision + precision\n",
        "    mean_recall = mean_recall + recall\n",
        "    mean_accuracy = mean_accuracy + accuracy\n",
        "    mean_query_ratio = mean_query_ratio + query_ratio\n",
        "    mean_relevant_ratio = mean_relevant_ratio + relevant_ratio\n",
        "\n",
        "    gemprecision, gemrecall, gemaccuracy = gsc[0], gsc[1], gsc[2]\n",
        "    gemmean_precision = gemmean_precision + gemprecision\n",
        "    gemmean_recall = gemmean_recall + gemrecall\n",
        "    gemmean_accuracy = gemmean_accuracy + gemaccuracy\n",
        "\n",
        "  nd_precisions.append(mean_precision / len(indices))\n",
        "  nd_recalls.append(mean_recall / len(indices))\n",
        "  nd_accuracies.append(mean_accuracy / len(indices))\n",
        "\n",
        "  nd_precisions_gem.append(gemmean_precision / len(indices))\n",
        "  nd_recalls_gem.append(gemmean_recall / len(indices))\n",
        "  nd_accuracies_gem.append(gemmean_accuracy / len(indices))\n",
        "\n",
        "  print(\"Results for threshold: \", threshold / 10)\n",
        "  print(\"Recall:                \", mean_recall / len(indices))\n",
        "  print(\"Precision:             \", mean_precision / len(indices))\n",
        "  print(\"Accuracy:              \", mean_accuracy / len(indices))\n",
        "\n",
        "  print(\"gemRecall:             \", gemmean_recall / len(indices))\n",
        "  print(\"gemPrecision:          \", gemmean_precision / len(indices))\n",
        "  print(\"gemAccuracy:           \", gemmean_accuracy / len(indices))\n",
        "\n",
        "  print(\"Queried % of database: \", mean_query_ratio / len(indices))\n",
        "  print(\"True Positive Ratio:   \", mean_relevant_ratio / len(indices))\n",
        "  print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXewbiuAlAGs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8tX6vd_rKLT"
      },
      "source": [
        "# SIMILAR IMAGE EVALUATION WITH ALL QUERIES\n",
        "\n",
        "query_index = 0\n",
        "\n",
        "nd_precisions = []\n",
        "nd_recalls = []\n",
        "nd_accuracies = []\n",
        "\n",
        "nd_precisions_gem = []\n",
        "nd_recalls_gem = []\n",
        "nd_accuracies_gem = []\n",
        "\n",
        "for threshold in np.arange(0, 15, 0.1):\n",
        "  mean_precision = 0\n",
        "  mean_recall = 0\n",
        "  mean_accuracy = 0\n",
        "  mean_query_ratio = 0\n",
        "  mean_relevant_ratio = 0\n",
        "\n",
        "  gemmean_precision = 0\n",
        "  gemmean_recall = 0\n",
        "  gemmean_accuracy = 0\n",
        "  gemmean_query_ratio = 0\n",
        "  gemmean_relevant_ratio = 0\n",
        "\n",
        "  \n",
        "\n",
        "  indices = list(range(queries.shape[0]))\n",
        "  indices.remove(15)\n",
        "  indices.remove(2)\n",
        "  indices.remove(18)\n",
        "\n",
        "  for query_index in indices:\n",
        "\n",
        "    query_vector = queries[query_index]\n",
        "    query_label = query_labels[query_index]\n",
        "    candidates = do_query(query_vector)\n",
        "    filtered = filter_results(vectors, candidates, query_vector, threshold / 10).flatten()\n",
        "    ground_truth = filter_results(vectors, np.arange(0, vectors.shape[0]), query_vector, threshold / 10).flatten()\n",
        "\n",
        "    same_label_ids = np.where(labels == query_label)[0]\n",
        "\n",
        "    # Remove Same Duplicates\n",
        "    # filtered = np.array([x for x in filtered if (x not in same_label_ids)])\n",
        "    # ground_truth = np.array([x for x in ground_truth if x not in same_label_ids])\n",
        "    # _vectors = []\n",
        "    \n",
        "    # for i, v in enumerate(vectors):\n",
        "    #   if labels[i] != query_label:\n",
        "    #     _vectors.append(v)\n",
        "    # _vectors = np.array(_vectors)\n",
        "\n",
        "    gem_recall, gem_qr, gem_rr, gem_fp, gem_fn = evaluate_hash_candidates(ground_truth, ground_truth, query_vector, vectors, ground_truth=ground_truth)\n",
        "    recall, query_ratio, relevant_ratio, fp, fn = evaluate_hash_candidates(candidates, filtered, query_vector, vectors, ground_truth=ground_truth)\n",
        "    \n",
        "    sc,ic = evaluate_result(filtered, labels, query_label)\n",
        "    gsc,gic = evaluate_result(ground_truth, labels, query_label)\n",
        "\n",
        "    precision, recall, accuracy = ic[0], ic[1], ic[2]\n",
        "    mean_precision = mean_precision + precision\n",
        "    mean_recall = mean_recall + recall\n",
        "    mean_accuracy = mean_accuracy + accuracy\n",
        "    mean_query_ratio = mean_query_ratio + query_ratio\n",
        "    mean_relevant_ratio = mean_relevant_ratio + relevant_ratio\n",
        "\n",
        "    gemprecision, gemrecall, gemaccuracy = gic[0], gic[1], gic[2]\n",
        "    gemmean_precision = gemmean_precision + gemprecision\n",
        "    gemmean_recall = gemmean_recall + gemrecall\n",
        "    gemmean_accuracy = gemmean_accuracy + gemaccuracy\n",
        "\n",
        "  nd_precisions.append(mean_precision / len(indices))\n",
        "  nd_recalls.append(mean_recall / len(indices))\n",
        "  nd_accuracies.append(mean_accuracy / len(indices))\n",
        "\n",
        "  nd_precisions_gem.append(gemmean_precision / len(indices))\n",
        "  nd_recalls_gem.append(gemmean_recall / len(indices))\n",
        "  nd_accuracies_gem.append(gemmean_accuracy / len(indices))\n",
        "\n",
        "  print(\"Results for threshold: \", threshold / 10)\n",
        "  print(\"Recall:                \", mean_recall / len(indices))\n",
        "  print(\"Precision:             \", mean_precision / len(indices))\n",
        "  print(\"Accuracy:              \", mean_accuracy / len(indices))\n",
        "  print(\"gemRecall:             \", gemmean_recall / len(indices))\n",
        "  print(\"gemPrecision:          \", gemmean_precision / len(indices))\n",
        "  print(\"gemAccuracy:           \", gemmean_accuracy / len(indices))\n",
        "  print(\"Queried % of database: \", mean_query_ratio / len(indices))\n",
        "  print(\"True Positive Ratio:   \", mean_relevant_ratio / len(indices))\n",
        "  print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfGoJ3vkmbFC"
      },
      "source": [
        "sc_ev, ic_ev = evaluate_result(filtered, labels, query_label)\n",
        "sc_precision, sc_recall, sc_accuracy = sc_ev\n",
        "ic_precision, ic_recall, ic_accuracy = ic_ev\n",
        "print(sc_ev, ic_ev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfw-RqrteIi8"
      },
      "source": [
        "x_axis = np.arange(0, 15, 0.1) / 10\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7,5))\n",
        "ax.plot(x_axis, nd_recalls, label=\"recall\")\n",
        "ax.plot(x_axis, nd_precisions, label=\"precision\")\n",
        "ax.plot(x_axis, nd_accuracies, label=\"accuracy\")\n",
        "ax.legend(loc=\"center left\")\n",
        "ax.set_xlabel('Cosine distance threshold')\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7,5))\n",
        "ax.plot(x_axis, nd_recalls_gem, label=\"recall\")\n",
        "ax.plot(x_axis, nd_precisions_gem, label=\"precision\")\n",
        "ax.plot(x_axis, nd_accuracies_gem, label=\"accuracy\")\n",
        "ax.legend(loc=\"center left\")\n",
        "ax.set_xlabel('Cosine distance threshold')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}