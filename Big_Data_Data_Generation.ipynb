{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Big_Data_Data_Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "obpVklN5ohfV"
      },
      "source": [
        "# Author Markus Laubenthal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARAmpLtYeZd1"
      },
      "source": [
        "!mkdir -p input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzhLXOEKmkIl"
      },
      "source": [
        "!mkdir -p input/base \n",
        "!mkdir -p input/query\n",
        "!mkdir -p input/ground_truth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1nnLnAZRgJc"
      },
      "source": [
        "!wget https://aev-autonomous-driving-dataset.s3.eu-central-1.amazonaws.com/a2d2-preview.tar --no-verbose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FICOo5sPOtMU"
      },
      "source": [
        "!wget https://storage.googleapis.com/laubenthal_spatiolab/kaffeemaschinen.zip -O input/ground_truth/kaffeemaschinen.zip --no-verbose\n",
        "!wget https://storage.googleapis.com/laubenthal_spatiolab/200x200coffee.zip -O input/ground_truth/200x200xcoffee.zip --no-verbose\n",
        "!wget https://storage.googleapis.com/laubenthal_spatiolab/horses.zip -O input/ground_truth/horses.zip --no-verbose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5tXNr9X6-IN"
      },
      "source": [
        "!wget https://storage.googleapis.com/laubenthal_spatiolab/Archiv.zip -O input/base/a2d2_alt.zip --no-verbose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDVPq8Ry7Iei"
      },
      "source": [
        "!unzip input/base/a2d2_alt.zip -d input/base/a2d2_alt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO-_G6PmZc0L"
      },
      "source": [
        "!tar -xf a2d2-preview.tar -C input/base\n",
        "!unzip input/ground_truth/kaffeemaschinen.zip -d input/ground_truth/kaffeemaschinen\n",
        "!unzip input/ground_truth/200x200xcoffee.zip -d input/ground_truth/kaffeemaschinen200\n",
        "!unzip input/ground_truth/horses.zip -d input/ground_truth/horses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Domhd4aJzshE"
      },
      "source": [
        "!rm -rf functions\n",
        "!git clone https://github.com/Lennard-Alms/lab_bd.git functions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOH8u6G-o1F5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "from sklearn.metrics import jaccard_score\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import h5py\n",
        "import keras\n",
        "from keras.layers import Input\n",
        "from keras import backend as K\n",
        "from keras import layers\n",
        "import gc\n",
        "from scipy.spatial import distance_matrix\n",
        "import seaborn as sns\n",
        "from operator import itemgetter \n",
        "from google.colab.patches import cv2_imshow\n",
        "from functions.preprocessing.BatchToFile import BatchProcessToFile\n",
        "from functions.preprocessing.FeatureExtractor import VGGFeatureExtractorMax\n",
        "from functions.preprocessing.FeatureExtractor import get_gem_model\n",
        "# from functions.preprocessing.FeatureExtracorMaxNoPatches import VGGFeatureExtractorMaxNoPatches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur2GpdKKnlmo"
      },
      "source": [
        "from functions.preprocessing.ImageMutation import PatchMutation\n",
        "from functions.preprocessing.HelperFunctions import get_patches_from_image, get_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbLSOKV2BsJu"
      },
      "source": [
        "coffeemachines = glob.glob('input/ground_truth/kaffeemaschinen200/*.png')[0:12]\n",
        "car_images_paths = list(glob.glob('input/base/a2d2_alt/**/*.png', recursive=True))\n",
        "horses = sorted(glob.glob('input/ground_truth/horses/horses/*.png'))\n",
        "h5_filename = \"max_result.h5\"\n",
        "car_images_paths.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEkVDMp_JHnU"
      },
      "source": [
        "horse_images = np.array([cv2.imread(horse, cv2.IMREAD_UNCHANGED) for horse in horses])\n",
        "trans_mask = horse_images[:,:,:,3] == 0\n",
        "\n",
        "#replace areas of transparency with white and not transparent\n",
        "_horse_images = horse_images.copy()\n",
        "_horse_images[trans_mask] = [255, 255, 255, 255]\n",
        "\n",
        "#new image without alpha channel...\n",
        "w_horse_images = np.empty((_horse_images.shape[0], _horse_images.shape[1], _horse_images.shape[2], 3)).astype(np.uint8)\n",
        "for index, whi in enumerate(w_horse_images):\n",
        "  w_horse_images[index] = cv2.cvtColor(_horse_images[index], cv2.COLOR_BGRA2BGR)\n",
        "# pm = PatchMutation(horse_images, mutation_probability=1, size=(100,100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUisI41-LA0J"
      },
      "source": [
        "# Create some Test Images for Report:\n",
        "pm100 = PatchMutation(horse_images[9:10], mutation_probability=1,size=(170,170))\n",
        "a2d2_patches = get_patches_from_image(get_image(car_images_paths[0]), window_size=(270,270), window_overlap=0)\n",
        "query_index = 0\n",
        "query_image = horse_images[query_index]\n",
        "db1, label = pm100.mutate(a2d2_patches[np.random.randint(0,20)])\n",
        "rquery = horse_images\n",
        "cv2_imshow(cv2.cvtColor(db1, cv2.COLOR_BGR2RGB))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug76eRhBgrEt"
      },
      "source": [
        "def get_angle_matrix(feature_vectors, feature_vectors_b = None):\n",
        "  if feature_vectors_b is None:\n",
        "    feature_vectors_b = feature_vectors.copy()\n",
        "  norms = np.linalg.norm(feature_vectors, axis=1)\n",
        "  norms_b = np.linalg.norm(feature_vectors_b, axis=1)\n",
        "  angle_matrix = (np.dot(feature_vectors, feature_vectors_b.T) / np.dot(norms[:,np.newaxis], norms_b[np.newaxis, :])).flatten().clip(-1,1)\n",
        "  angle_matrix = np.arccos(angle_matrix)\n",
        "  angle_matrix.sort()\n",
        "  return angle_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfw-RqrteIi8"
      },
      "source": [
        "def create_unmutated_dataset(label=\"unmutated_a2d2\"):\n",
        "  global car_images_paths\n",
        "  filename=\"a2d2.h5\"\n",
        "  ci_selection = np.random.randint(0,len(car_images_paths), 76)\n",
        "  cars = list(itemgetter(*ci_selection)(car_images_paths))\n",
        "  processor = VGGFeatureExtractorMax(window_size=(200,200), vgg_model=get_gem_model((200,200)))\n",
        "  batch_processor = BatchProcessToFile(filename)\n",
        "  batch_processor.batch(processor, cars, \"a2d2\", batch_size=12)\n",
        "# create_unmutated_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dykuusn4esk4"
      },
      "source": [
        "def create_mutated_dataset(mutation_probability=0.1, label=\"mutated_a2d2_coffee\"):\n",
        "  global car_images_paths\n",
        "  global coffeemachines\n",
        "  global h5_filename\n",
        "  mutation_strategy = PatchMutation(coffeemachines, mutation_probability=mutation_probability, size=(100,100))\n",
        "  processor = VGGFeatureExtractorMax(window_size=(200,200), mutation_strategy=mutation_strategy, vgg_model=get_gem_model())\n",
        "  batch_processor = BatchProcessToFile(h5_filename)\n",
        "  batch_processor.batch(processor, car_images_paths, label, batch_size=12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM3Np8k4CnP5"
      },
      "source": [
        "def create_fully_mutated_dataset(mutation_probability=1, label=\"mutated_a2d2_coffee_100\"):\n",
        "  global car_images_paths\n",
        "  global coffeemachines\n",
        "  global h5_filename\n",
        "  mutation_strategy = PatchMutation(coffeemachines, mutation_probability=mutation_probability, size=(100,100))\n",
        "  processor = VGGFeatureExtractorMax(window_size=(200,200), mutation_strategy=mutation_strategy, vgg_model=get_gem_model())\n",
        "  batch_processor = BatchProcessToFile(h5_filename)\n",
        "  batch_processor.batch(processor, car_images_paths, label, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfFocohMRzn4"
      },
      "source": [
        "def create_duplicate_test(mutation_probability=0.1, label=\"duplicate_test\"):\n",
        "  global horse_images\n",
        "  global w_horse_images\n",
        "  global car_images_paths\n",
        "  global coffeemachines\n",
        "  global h5_filename\n",
        "  \n",
        "  filename=\"duplicates.h5\"\n",
        "  # Select 10% of dataset\n",
        "  ci_selection = np.random.randint(0,len(car_images_paths), 76)\n",
        "  cars = list(itemgetter(*ci_selection)(car_images_paths))\n",
        "\n",
        "  for window_size in [(50,50), (100,100), (150,150), (200,200), (300,300), (400,400)]:\n",
        "    query_model = get_gem_model(window_size)\n",
        "    processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=query_model, extract_patches=False)\n",
        "    batch_processor = BatchProcessToFile(filename)\n",
        "    batch_processor.batch(processor, w_horse_images, 'query' + str(window_size), batch_size=128)\n",
        "\n",
        "  # Create A2D2 images with scaled horses x1\n",
        "  window_size=(300,300)\n",
        "  vgg_model = get_gem_model(window_size)\n",
        "  ms = PatchMutation(horse_images, mutation_probability=0.1, size=(200,200))\n",
        "  processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=vgg_model, extract_patches=True, mutation_strategy=ms)\n",
        "  batch_processor = BatchProcessToFile(filename)\n",
        "  batch_processor.batch(processor, cars, 'a2d2_background_scale_1_0', batch_size=12)\n",
        "\n",
        "  # Create A2D2 images with scaled horses x1.5\n",
        "  window_size=(400,400)\n",
        "  vgg_model = get_gem_model(window_size)\n",
        "  ms = PatchMutation(horse_images, mutation_probability=0.1, size=(300,300))\n",
        "  processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=vgg_model, extract_patches=True, mutation_strategy=ms)\n",
        "  batch_processor = BatchProcessToFile(filename)\n",
        "  batch_processor.batch(processor, cars, 'a2d2_background_scale_1_5', batch_size=12)\n",
        "\n",
        "  # Create A2D2 images with scaled horses x2\n",
        "  window_size=(500,500)\n",
        "  vgg_model = get_gem_model(window_size)\n",
        "  ms = PatchMutation(horse_images, mutation_probability=0.1, size=(400,400))\n",
        "  processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=vgg_model, extract_patches=True, mutation_strategy=ms)\n",
        "  batch_processor = BatchProcessToFile(filename)\n",
        "  batch_processor.batch(processor, cars, 'a2d2_background_scale_2_0', batch_size=12)\n",
        "\n",
        "  # Create A2D2 images with scaled horses x0.5\n",
        "  window_size=(150,150)\n",
        "  vgg_model = get_gem_model(window_size)\n",
        "  ms = PatchMutation(horse_images, mutation_probability=0.1, size=(100,100))\n",
        "  processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=vgg_model, extract_patches=True, mutation_strategy=ms)\n",
        "  batch_processor = BatchProcessToFile(filename)\n",
        "  batch_processor.batch(processor, cars, 'a2d2_background_scale_0_5', batch_size=12)\n",
        "\n",
        "  # Create A2D2 images with scaled horses x0.25\n",
        "  window_size=(100,100)\n",
        "  vgg_model = get_gem_model(window_size)\n",
        "  ms = PatchMutation(horse_images, mutation_probability=0.1, size=(50,50))\n",
        "  processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=vgg_model, extract_patches=True, mutation_strategy=ms)\n",
        "  batch_processor = BatchProcessToFile(filename)\n",
        "  batch_processor.batch(processor, cars, 'a2d2_background_scale_0_25', batch_size=12)\n",
        "\n",
        "create_duplicate_test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTw5NmhaXpxJ"
      },
      "source": [
        "def create_duplicate_test(mutation_probability=0.1, label=\"duplicate_test\"):\n",
        "  global horse_images\n",
        "  global w_horse_images\n",
        "  global car_images_paths\n",
        "  global coffeemachines\n",
        "  global h5_filename\n",
        "  \n",
        "  filename=\"duplicates.h5\"\n",
        "  # Select 10% of dataset\n",
        "  ci_selection = np.random.randint(0,len(car_images_paths), 76)\n",
        "  cars = list(itemgetter(*ci_selection)(car_images_paths))\n",
        "\n",
        "  # Create Query images in different sizes\n",
        "\n",
        "  for window_size in [(100,100), (150,150), (200,200), (300,300), (400,400)]:\n",
        "    query_model = get_gem_model(window_size)\n",
        "    processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=query_model, extract_patches=False)\n",
        "    batch_processor = BatchProcessToFile(filename)\n",
        "    batch_processor.batch(processor, w_horse_images, 'query' + str(window_size), batch_size=128)\n",
        "\n",
        "  # Create horse images on white Background\n",
        "  window_size=(300,300)\n",
        "  vgg_model = get_gem_model(window_size)\n",
        "  ms = PatchMutation(horse_images, mutation_probability=1, size=(200,200))\n",
        "  processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=vgg_model, extract_patches=False, mutation_strategy=ms)\n",
        "  batch_processor = BatchProcessToFile(filename)\n",
        "  batch_processor.batch(processor, np.full((100, 300, 300, 3), 255), 'white_background_horses', batch_size=128)\n",
        "\n",
        "  # Create A2D2 images with horses ~50% cover\n",
        "  window_size=(250,250)\n",
        "  vgg_model = get_gem_model(window_size)\n",
        "  ms = PatchMutation(horse_images, mutation_probability=0.1, size=(200,200))\n",
        "  processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=vgg_model, extract_patches=True, mutation_strategy=ms)\n",
        "  batch_processor = BatchProcessToFile(filename)\n",
        "  batch_processor.batch(processor, cars, 'a2d2_background_horses_50_cover', batch_size=12)\n",
        "\n",
        "  # Create A2D2 images with horses ~40% cover\n",
        "  window_size=(300,300)\n",
        "  vgg_model = get_gem_model(window_size)\n",
        "  ms = PatchMutation(horse_images, mutation_probability=0.1, size=(200,200))\n",
        "  processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=vgg_model, extract_patches=True, mutation_strategy=ms)\n",
        "  batch_processor = BatchProcessToFile(filename)\n",
        "  batch_processor.batch(processor, cars, 'a2d2_background_horses_40_cover', batch_size=12)\n",
        "\n",
        "  # Create A2D2 images with horses ~20% cover\n",
        "  window_size=(400,400)\n",
        "  vgg_model = get_gem_model(window_size)\n",
        "  ms = PatchMutation(horse_images, mutation_probability=0.1, size=(200,200))\n",
        "  processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=vgg_model, extract_patches=True, mutation_strategy=ms)\n",
        "  batch_processor = BatchProcessToFile(filename)\n",
        "  batch_processor.batch(processor, cars, 'a2d2_background_horses_20_cover', batch_size=12)\n",
        "\n",
        "  # Create A2D2 images with scaled horses x1.5\n",
        "  window_size=(400,400)\n",
        "  vgg_model = get_gem_model(window_size)\n",
        "  ms = PatchMutation(horse_images, mutation_probability=0.1, size=(300,300))\n",
        "  processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=vgg_model, extract_patches=True, mutation_strategy=ms)\n",
        "  batch_processor = BatchProcessToFile(filename)\n",
        "  batch_processor.batch(processor, cars, 'a2d2_background_scale_1_5', batch_size=12)\n",
        "\n",
        "  # Create A2D2 images with scaled horses x2\n",
        "  # filename=\"test.h5\"\n",
        "  window_size=(500,500)\n",
        "  vgg_model = get_gem_model(window_size)\n",
        "  ms = PatchMutation(horse_images, mutation_probability=0.1, size=(400,400))\n",
        "  processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=vgg_model, extract_patches=True, mutation_strategy=ms)\n",
        "  batch_processor = BatchProcessToFile(filename)\n",
        "  batch_processor.batch(processor, cars, 'a2d2_background_scale_2_0', batch_size=12)\n",
        "\n",
        "  # Create A2D2 images with scaled horses x0.5\n",
        "  window_size=(150,150)\n",
        "  vgg_model = get_gem_model(window_size)\n",
        "  ms = PatchMutation(horse_images, mutation_probability=0.1, size=(100,100))\n",
        "  processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=vgg_model, extract_patches=True, mutation_strategy=ms)\n",
        "  batch_processor = BatchProcessToFile(filename)\n",
        "  batch_processor.batch(processor, cars, 'a2d2_background_scale_0_5', batch_size=12)\n",
        "\n",
        "  # Create A2D2 images with scaled horses x0.25\n",
        "  window_size=(100,100)\n",
        "  vgg_model = get_gem_model(window_size)\n",
        "  ms = PatchMutation(horse_images, mutation_probability=0.1, size=(50,50))\n",
        "  processor = VGGFeatureExtractorMax(window_size=window_size, vgg_model=vgg_model, extract_patches=True, mutation_strategy=ms)\n",
        "  batch_processor = BatchProcessToFile(filename)\n",
        "  batch_processor.batch(processor, cars, 'a2d2_background_scale_0_25', batch_size=12)\n",
        "create_duplicate_test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UMiaZC-fK5y"
      },
      "source": [
        "with h5py.File('duplicates.h5', 'r') as f:\n",
        "  for key in f.keys():\n",
        "    print(key)\n",
        "    print(f[key].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbzWZHQLijPM"
      },
      "source": [
        "def create_white_background_coffeemachines(label=\"white_coffee\", scale=1):\n",
        "  global coffeemachines\n",
        "  global h5_filename\n",
        "  if scale != 1:\n",
        "    label = label + \"_scale_\" + str(scale)\n",
        "  white_images = np.full((500,200,200,3), 255, dtype=np.uint8)\n",
        "  mutation_strategy = PatchMutation(coffeemachines, mutation_probability=1, size=(int(scale * 100),int(scale * 100)))\n",
        "  processor = VGGFeatureExtractorMax(window_size=(200,200), mutation_strategy=mutation_strategy, extract_patches=False, vgg_model=get_gem_model())\n",
        "  batch_processor = BatchProcessToFile(h5_filename)\n",
        "  batch_processor.batch(processor, white_images, label, batch_size=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6jPbKmCtnu6"
      },
      "source": [
        "def create_original_coffeemachines(label=\"original_coffeemachines\"):\n",
        "  global coffeemachines\n",
        "  global h5_filename\n",
        "  with h5py.File(h5_filename, 'a') as f:\n",
        "    if label in f:\n",
        "      del f[label]\n",
        "  mutation_strategy = None\n",
        "  processor = VGGFeatureExtractorMax(window_size=(200,200), mutation_strategy=mutation_strategy, extract_patches=False, vgg_model=get_gem_model())\n",
        "  batch_processor = BatchProcessToFile(h5_filename)\n",
        "  batch_processor.batch(processor, coffeemachines, label, batch_size=32)\n",
        "\n",
        "  with h5py.File(h5_filename, 'a') as f:\n",
        "    dataset_name = label + \"_label\"\n",
        "    if dataset_name in f:\n",
        "      del f[dataset_name]\n",
        "    f.create_dataset(dataset_name, (len(coffeemachines), 1))\n",
        "    dataset = f[dataset_name]\n",
        "    for i, cm in enumerate(coffeemachines):\n",
        "      dataset[i] = np.array([i])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_8GriEIs2Pk"
      },
      "source": [
        "create_original_coffeemachines()\n",
        "create_white_background_coffeemachines()\n",
        "create_white_background_coffeemachines(scale=0.5)\n",
        "create_white_background_coffeemachines(scale=0.25)\n",
        "create_white_background_coffeemachines(scale=1.5)\n",
        "create_fully_mutated_dataset()\n",
        "create_mutated_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_Gd-0c0pB_A"
      },
      "source": [
        "def remove_if_exists(f, key):\n",
        "  if key in f:\n",
        "    del f[key]\n",
        "with h5py.File('max_result.h5', 'r') as f:\n",
        "  remove_if_exists(f, 'unmutated_a2d2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVDNTF47mxBZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki4u9j8doB_r"
      },
      "source": [
        "f = h5py.File(h5_filename, 'a')\n",
        "remove_if_exists(f, 'unmutated_a2d2')\n",
        "f.close()\n",
        "create_unmutated_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXPS3sfg0QO7"
      },
      "source": [
        "f = h5py.File(h5_filename, 'a')\n",
        "remove_if_exists(f, 'mutated_a2d2_coffee_10')\n",
        "remove_if_exists(f, 'mutated_a2d2_coffee_label_10')\n",
        "f.close()\n",
        "create_mutated_dataset(mutation_probability=0.1, label=\"mutated_a2d2_coffee_10\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM4jEurYM0ND"
      },
      "source": [
        "f = h5py.File(h5_filename, 'a')\n",
        "remove_if_exists(f, 'mutated_a2d2_coffee_100')\n",
        "remove_if_exists(f, 'mutated_a2d2_coffee_label_100')\n",
        "f.close()\n",
        "create_fully_mutated_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X24uj3wN8vX"
      },
      "source": [
        "f = h5py.File(h5_filename, 'a')\n",
        "remove_if_exists(f, 'white_coffee')\n",
        "remove_if_exists(f, 'white_coffee_label')\n",
        "f.close()\n",
        "create_white_background_coffeemachines()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}